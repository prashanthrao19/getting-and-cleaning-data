?read.table
flights<- read.table("./flights.csv",header = TRUE,sep=",")
class(flights)
library(data.table)
class(flights)
as.data.table(flights)
class(flights)
AA<-as.data.table(flights)
class(AA)
rm("flights")
class(flights)
AA["JFK"]
AA[origin == "JFK"]
setkey(AA,"origin","dest")
key(AA)
AA["JFK",max(dep_delay),by = month][order(month)]
AA["JFK",max(dep_delay),by = month]
AA["JFK",max_dep_delay=max(dep_delay),by = month][order(max_dep_delay)]
AA["JFK",max_dep_delay:=max(dep_delay),by = month][order(max_dep_delay)]
install.packages(reshape2)
?dcast
R.home()
MYSQL_HOME=C:/PROGRA~1/R/R-32~1.1/
MYSQL_HOME=C:\\PROGRA~1\\R\\R-32~1.1\\
MYSQL_HOME=C:\\PROGRA~1\\R\\R-32~1.1\\
MYSQL_HOME=C:\\PROGRA~1\\R\\R-32~1.1\
MYSQL_HOME = C:\\PROGRA~1\\R\\R-32~1.1\
install.packages("RMySQL",type = 'SOURCE')
install.packages("RMySQL",type = 'Source')
install.packages(Rtools)
install.packages("Rtools")
install.packages("RMySQL",type = "source")
librart(RmySQL)
library(RmySQL)
library(RMySQL)
source("https://bioconductor.org/biocLite.R")
biocLite("rhdf5")
library(rhdf5)
created<- h5createFile("example.h5")
created
created<- h5createGroup("example.h5","foo")
created<- h5createGroup("example.h5","baa")
created<- h5createGroup("example.h5","foo/baa")
h5ls("example.h5")
library(httr)
oauth_endpoints("github")
myapp<-oauth_app("github",key="db17b630f36868b8b0be",secret = "3297eb874802d1cd6e818c190efef61e75040747")
github_token <- oauth2.0_token(oauth_endpoint("github"),myapp)
github_token <- oauth2.0_token(oauth_endpoint("github"),myapp)
github_token <- oauth2.0_token(oauth_endpoints("github"),myapp)
gtoken<-config(token = github_token)
req<-GET("https://api.github.com/users/jtleek/repos",gtoken)
stop_for_status(req)
oauth_endpoints("github")
myapp<-oauth_app("github",key="db17b630f36868b8b0be",secret = "3297eb874802d1cd6e818c190efef61e75040747")
github_token <- oauth2.0_token(oauth_endpoints("github"),myapp)
gtoken<-config(token = github_token)
req<-GET("https://api.github.com/users/jtleek/repos",gtoken)
stop_for_status(req)
install.packages("httpuv")
library(jsonlite)
library(httr)
oauth_endpoints("github")
myapp<-oauth_app("github",key = "db17b630f36868b8b0be",secret = "38c145ef94da1fc493ba0c5d59bc371f37eb606f
")
myapp<-oauth_app("github",key = "db17b630f36868b8b0be",secret = "38c145ef94da1fc493ba0c5d59bc371f37eb606f")
github_token<- oauth2.0_token(oauth_endpoints("github"),myapp)
gtoken<-config( token = github_token)
req<-GET("https://api.github.com/users/jtleek/repos",gtoken)
stop_for_status()
stop_for_status(req)
repocontent<-content(req)
AA<- content(req)
library(jsonlite)
install.packages(jsonlite)
install.packages("jsonlite")
AA<- content(req)
library(jsonlite)
library(jsonlite)
library("jsonlite")
library("Jsonlite")
library(Json)
library(JSON)
?jsonlite
?Json
?JSON
?fromJSON
install.packages("jsonlite")
library(jsonlite)
library(jsonlite)
library(RMySQL)
library(sqldf)
install.packages("sqldf")
acs<-fread("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06pid.csv" )
library(data.table)
acs<-fread("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06pid.csv" )
a<-sqldf("select * from acs where AGEP <50 and pwgtp1)
a<-sqldf("select * from acs where AGEP <50 and pwgtp1")
library(sqldf)
a<-sqldf("select * from acs where AGEP <50 and pwgtp1")
?"sqldf"
a<-sqldf("select * from acs where AGEP <50 and pwgtp1",password="rao")
a<-sqldf("select * from acs where AGEP <50 and pwgtp1",rao@localhost,password = "rao")
a<-sqldf("select * from acs where AGEP <50 and pwgtp1",password = "rao")
a<-sqldf("select * from acs where AGEP <50 and pwgtp1")
a<-sqldf("select * from acs where AGEP <50 and pwgtp1",password = "rao1991")
a<-sqldf("select * from acs where AGEP <50 and pwgtp1")
fileurl<-"http://biostat.jhsph.edu/~jleek/contact.html"
library(XML)
html<- htmlTreeParse(fileurl,useInternalNodes = T)
xpathSApply(html,/10)
html
html<- readLines(html)
xpathSApply(html,"//title",xmlValue)
class(html)
html[1:9]
con<- url("http://biostat.jhsph.edu/~jleek/contact.html")
htmlcode<- readlines(con)
htmlcode<- readLines(con)
htmlcode
close(con = )
close(con)
class(htmlcode)
htmlcode[1:9]
html[1:9,no=nchar(1.9)]
html[1:9,no=nchar(1:9)]
htmlcode[nchar(1:9)]
?nchar
X>-htmlcode[1:9]
X<-htmlcode[1:9]
X
nchar(X,type = "chars")
X<-htmlcode[c(10,20,30,100)]
nchar(X,type = "chars")
?for
??.for
x<- read.fwf(file = url("https://d396qusza40orc.cloudfront.net/getdata%2Fwksst8110.for"),skip=4,widths = c(12,7,4,9,4,9,4,9,4))
head(x)
?read.fwf
class(x)
y<-as.data.table(x)
class(y)
y[,sum(4)]
y[,4]
y[4]
x$V4
A<-sum(x$V4)
A
x
head(x)
A<-sum(x$V4)
A
class(x)
gdp<- read.csv("./GDP.csv")
head(gdp)
tail(gdp)
edu<-read.csv("./edu.csv")
match<- gdp$code %in% edu$CountryCode
match
sum(match)
?merge
gdp_edu <- merge.data.frame(gdp,edu,by.x = "code",by.y = "CountryCode")
gdp_edu
head(gdp_edu)
?cut
gdpedu_groups<- cut(gdp_edu,breaks= quantile(gdp_edu$Ranking))
str(gdp_edu)
gdpedu_groups<- cut(gdp_edu$Ranking,breaks= quantile(gdp_edu$Ranking))
gdpedu_groups<- cut(gdp_edu$Ranking,breaks= quantile(gdp_edu$Ranking),na.rm = TRUE)
gdpedu_groups<- cut(gdp_edu$Ranking,breaks= quantile(gdp_edu$Ranking,na.rm = TRUE))
head(gdpedu_groups)
gdpedu_groups
?quantile
gdpedu_groups<- cut(gdp_edu$Ranking,breaks= quantile(gdp_edu$Ranking,probs = seq(0,1,0.2),na.rm = TRUE))
gdpedu_groups
table(gpdedu_groups)
table(gpdedu_group)
table(gdpedu_groups)
table(gdpedu_groups,gdp_edu$Income.Group)
table<-table(gdpedu_groups,gdp_edu$Income.Group)
names(table)
head(table)
head(gdp_edu,n=1)
gdp_ranking<- select(gdp_edu,Ranking,Income.Group)
library(dplyr)
gdp_ranking<- select(gdp_edu,Ranking,Income.Group)
head(gdp_ranking)
head_ranking<- arrange(gdp_ranking,Income.Group)
head(gdp_ranking)
head(head_ranking)
head_ranking<- arrange(gdp_ranking,desc(Income.Group))
head(head_ranking)
?melt
library(reshape2)
?melt
melt_gdpranking<- dcast(head_ranking,Income.Group ~ variable)
melt_gdpranking<- dcast(head_ranking,Income.Group ~ Ranking)
melt_gdpranking
melt_gdpranking<- dcast(head_ranking,ranking ~ Income.Group)
melt_gdpranking<- dcast(head_ranking,Ranking ~ Income.Group)
melt_gdpranking
melt_gdpranking<- dcast(head_ranking,Ranking ~ Income.Group,mean)
melt_gdpranking
melt_gdpranking<- dcast(head_ranking,Income.Group ~ Ranking)
melt_gdpranking<- dcast(head_ranking,Income.Group ~ Ranking,mean)
melt_gdpranking
gdp_ranking
class(gdp_ranking)
cut_ranking <- cut(gdp_ranking,breaks = Income.Group)
cut_ranking <- cut(gdp_ranking$Income.Group,breaks = Income.Group)
cut_ranking <- cut(gdp_ranking$Ranking.Group,breaks = Income.Group)
cut_ranking <- cut(gdp_ranking$Ranking,breaks = Income.Group)
cut_ranking <- cut(gdp_ranking$Ranking,breaks = "Income.Group")
library(data.table)
mean_ranking<-gdp_ranking[,keyby=Income.Group]
mean_ranking<-gdp_ranking[,mean_rank = mean(Ranking),by=Income.Group]
mean_ranking<-gdp_ranking[,mean_rank := mean(Ranking),by = Income.Group]
mean_ranking<-gdp_ranking[,mean_rank := mean(Ranking),by := Income.Group]
mean_ranking<-gdp_ranking[,mean_rank := mean(Ranking),keyby = Income.Group]
sorted_ranking<- setkey(gdp_ranking,Income.Group)
class(gdp_ranking)
gdp_ranking<as.data.table(gdp_ranking)
gdp_ranking<- as.data.table(gdp_ranking)
sorted_ranking<- setkey(gdp_ranking,Income.Group)
sorted_ranking
mean_ranking<- sorted_ranking[,mean_rank := mean(Ranking,na.rm = T),by = Income.Group]
mean_ranking
View(mean_ranking)
View(mean_ranking)
gdp<- read.csv("./GDP.csv")
head(gdp)
tail(gdp)
matches<- gdp$code %in% edu$CountryCode
sum(matches)
sorted_gdp<-arrange(gdp,by = desc(Ranking))
sorted_gdp
sorted_gdp<-arrange(gdp,by = desc(Ranking),na.rm= TRUE)
sorted_gdp<-arrange(gdp,by = desc(Ranking),na.rm = TRUE)
na<- is.na(gdp$Ranking)
gdp<- gdp[na]
gdp<- gdp[na,]
head(gdp)
tail(gdp)
View(gdp)
View(gdp)
View(gdp)
gdp<- read.csv("./GDP.csv",fill=F)
head(gdp)
tail(gdp)
matches<- gdp$code %in% edu$CountryCode
matches
sum(matches)
sorted_gdp<- arrange(gdp,desc(Ranking),na.omit(Ranking))
sorted_gdp<- arrange(gdp,desc(Ranking))
sorted_gdp<- arrange(gdp,desc(Ranking,na.omit(Ranking)))
head(sorted_gdp)
head(sorted_gdp,n=20)
gdp_edu<- merge.data.frame(gdp,edu,by.x = Code,by.y = CountryCode)
gdp_edu<- merge.data.frame(gdp,edu,by.x = code,by.y = CountryCode)
gdp_edu<- merge.data.frame(gdp,edu,by.x = "code",by.y = "CountryCode")
cut_gdp <- cut(gdp_edu$Ranking,breaks= quantile(gdp_edu$Ranking, probs = seq(0,1,0.2)))
cut_gdp
cut_gdp_table<- table(cut_gdp,gdp_edu$Income.Group)
cut_gdp_table
save(gdp,gdp_edu,gdp_ranking,gdpedu_groups,"./gdp.rda")
save(gdp,gdp_edu,gdp_ranking,gdpedu_groups,file = "./gdp.rda")
load("~/gdp.rda")
data()
library(ggplot)
library(ggplot2)
install.packages("ggplot2")
data()
data(ggplot2)
data("ggplot2")
data(package = "ggplt2")
data(package = "ggplot2")
is.na(airquality$Ozone)
tf<-is.na(airquality$Ozone)
airquality$Ozone[tf]<-0
duplicated(iris)
sum(duplicated(iris))
class(iris$Species)
iris$Species[1:5]
str(mtcars)
mtcars$gear<- as.factor(mtcars$gear)
str(mtcars)
str(mtcars$gear)
table(mtcars$gear)
table(mtcars$vs)
glimpse(movies)
library(ggplot2)
glimpse(movies)
?glimpse
??glimpse
library(dplyr)
glimpse(movies)
pretty_movies<- tbl_df(movies)
movies
head(movies)
head(pretty_movies)
pretty_movies
1000 %>% sqrt
1000 %>% sqrt %>% round
?tbl_df
class(movies)
group_by(movies,year) %>% avg_rating <- mutate(avg_rating = mean(rating))
group_by(movies,year) %>% mutate(avg_rating = mean(rating))
group_by(movies,year) %>% mutate(avg_rating = mean(rating)) %>% summarise(year,avg_rating)
group_by(movies,year) %>% mutate(avg_rating = mean(rating)) %>% summarise(avg_rating)
group_by(movies,year) %>% mutate(avg_rating = mean(rating)) %>% select(year,avg_rating)
fileurl<- https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06hid.csv
fileurl<- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06hid.csv"
download.file(fileurl,"./hosuing.csv")
housing<- read.csv("./housing.csv")
housing<- read.csv("./hosuing.csv")
names(housing)
?strsplit
splitnames<- strsplit(names(housing),"\[0-9]")
splitnames<- strsplit(names(housing),"[0-9]")
splitnames[123]
splitnames[124]
splitnames
fileurl<-"https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FGDP.csv "
download.file(fileurl,"./gdp.csv")
gdp<-read.csv("./gdp.csv")
gdp
gdp<-read.csv("./gdp.csv",skip = 4)
gdp
head(gdp)
gdp<- select(X,X.1,X.3,X.4)
gdp<- select(gdp,X,X.1,X.3,X.4)
head(gdp)
mean(gdp$X.4,na.rm = TRUE)
gsub(",","",gdp$X.4)
head(gdp)
gdp_value<-gsub(",","",gdp$X.4)
average<- mean(gdp_value)
class(gdp_value)
gdp_value<- as.numeric(gdp_value)
gdp_value<- as.numeric(gdp_value,na.omit=T)
class(gdp_value)
average<- mean(gdp_value)
average
gdp_value
average<- mean(gdp_value,na.rm = T)
average
average<- mean(gdp_value[1:190],na.rm = T)
average
head(gdp)
gdp<-gdp[1:190]
gdp<-gdp[,1:190]
gdp<-gdp[1:190,]
tail(gdp)
grep("^United",gdp$X.4)
grep("^United",gdp$X.3)
fileurl<-"https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FEDSTATS_Country.csv"
download.file(fileurl,"./edu.csv")
edu<-read.csv("./edu.csv")
edu
head(edu,2)
View(gdp)
View(gdp)
gdp_edu<- merge.data.frame(gdp,edu,by.x = "X",by.y = "CountryCode")
View(gdp_edu)
gdp_select<- select(gdp_edu,X,X.3,Special.Notes)
View(gdp_select)
View(gdp_select)
june_fiscal<-grep("[Jj]une",gdp_select$Special.Notes)
june_fiscal
sum(june_fiscal)
length(june_fiscal)
june_fiscal<-grepl("[Jj]une",gdp_select$Special.Notes)
june_fiscal
june_fiscal<-grep("[Jj]une",gdp_select$Special.Notes)
june_fiscal
june_fiscal<-grep("[J]une",gdp_select$Special.Notes)
june_fiscal
june_fiscal<-grep("[J]une",gdp_select$Special.Notes,value = TRUE)
june_fiscal
june_fiscal<-grep("Fiscal year end: June 30",gdp_select$Special.Notes,value = TRUE)
june_fiscal
length(june_fiscal)
library(quantmod)
install.packages("quantmod")
library(quantmod)
amzn<- getSymbols("AMZN",auto.assign = False)
amzn<- getSymbols("AMZN",auto.assign = FALSE)
sampleTimes<- index(amzn)
head(sampleTimes)
class(sampleTimes)
in2012<- sampleTimes %in% 2012
in2012
in2012<- sampleTimes %in% "2012"
in2012
in2012<- sampleTimes >"01-01-2012"
iin2012
in2012
in2012<- (sampleTimes - ("01-01-2012"))<365
in2012<- (sampleTimes - 01-01-2012)<365
in2012
in2012<- (sampleTimes - dmy("01-01-2012")<365
)
library(lubridate)
in2012<- (sampleTimes - dmy("01-01-2012")<365)
in2012<- years(sampleTimes) = 2012
in2012 <- years(sampleTimes) = 2012
in2012 <- years(sampleTimes)
in2012
sampleTimes
class(sampleTimes)
d1<-dmy("01-01-2012")
class(d1)
in2012<- sampleTimes - d1
d1<- as.Date(d1,%d%m%Y)
d1<- as.Date(d1,%d%b%Y)
d1<- as.Date(d1,"%d%m%Y")
d1
in2012<- sampleTimes - d1
in2012
in2012<- (sampleTimes - d1) < 0
sum(in2012)
in2012
in2012<- (sampleTimes - d1) < 365
sum(in2012)
in2012<- (sampleTimes - d1) < 365 & (sampleTimes - d1) > 0
sum(in2012)
in2012<- (sampleTimes - d1) < 366 & (sampleTimes - d1) > 0
sum(in2012)
in2012<- (sampleTimes - d1) < 365 & (sampleTimes - d1) >= 0
sum(in2012)
in2012<- (sampleTimes - d1) <= 365 & (sampleTimes - d1) >= 0
sum(in2012)
2012_values<- sampleTimes[in2012]
2012_values<- sampleTimes["in2012"]
2012_values<- sampleTimes(in2012)
2012_values<- subset(sampleTimes,intime)
2012_values<- subset(sampleTimes,intime = T)
in2012
in2012[1]
grep("TRUE",in2012)
index<-grep("TRUE",in2012)
2012_values <- sampleTimes[index]
2012_values <- sampleTimes[index,]
2012_values <- sampleTimes["index"]
2012_values <- sampleTimes[c(index)]
2012_values <- sampleTimes[1]
class(sampleTimes)
sample<- as.data.frame(sampleTimes)
sample
head(sample)
sample[iindex]
sample[index]
sample["index"]
class(sample$sampleTimes)
index
sample[1261:1510]
sample[1261:1510,]
2012<-sample[1261:1510,]
yr <- sample[1261:1510,]
yr
day<- wday(yr[1])
day
day<- wday(yr)
day
day<- wday(yr) = 2
day<- (wday(yr) = 2)
length(day)
day
day<- (wday(yr) == 2)
day
length(day)
day<- wday(yr)
table(day)
day
yr
day<- wday(yr)
day
yr<- sample[1261:1510,]
yr
day<- wday(yr)
day
table(yr)
table(day)
housing
names<- strsplit(names(housing),"[0-9]")
names
names<- strsplit(names(housing))
names<- strsplit(names(housing),"wgtp")
names[123]
download.file("https://d396qusza40orc.cloudfront.net/getdata%2Fprojectfiles%2FUCI%20HAR%20Dataset.zip","./samsung")
?read.txt
??read.txt
test <- read.table("C:\\Users\\rao\\Documents\\UCI HAR Dataset\test\X_test.txt")
test <- read.table("C:\\Users\\rao\\Documents\\UCI HAR Dataset\\test\\X_test.txt")
head(test)
class(test)
test <- read.table("C:\\Users\\rao\\Documents\\UCI HAR Dataset\\test\\y_test.txt")
test2 <- read.table("C:\\Users\\rao\\Documents\\UCI HAR Dataset\\test\\y_test.txt")
test <- read.table("C:\\Users\\rao\\Documents\\UCI HAR Dataset\\test\\X_test.txt")
test2
head(test2)
train_x<- read.table("C:\\Users\\rao\\Documents\\UCI HAR Dataset\\train\\X_train.txt")
train_y<- read.table("C:\\Users\\rao\\Documents\\UCI HAR Dataset\\train\\y_train.txt")
test_x <- read.table("C:\\Users\\rao\\Documents\\UCI HAR Dataset\\test\\X_test.txt")
rm(test)
test_y <- read.table("C:\\Users\\rao\\Documents\\UCI HAR Dataset\\test\\y_test.txt")
rm(test2)
source("./run_analysis.R")
View(run_analysis)
View(run_analysis)
source('~/run_analysis.R')
run_analysis()
